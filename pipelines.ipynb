{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/universe_bright/Workarea/Projects/PersonalProjects/HuggingFaceExamples/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from transformers import pipeline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.999882698059082},\n",
       " {'label': 'NEGATIVE', 'score': 0.9993650317192078},\n",
       " {'label': 'NEGATIVE', 'score': 0.9928938746452332}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier([\"It is a good day!\", \"I feel pain.\", \"Here is a bus stop.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'It is a good day!',\n",
       "  'labels': ['Good', 'Neutral', 'Bad'],\n",
       "  'scores': [0.9697498679161072, 0.028081024065613747, 0.002169129205867648]},\n",
       " {'sequence': 'I feel pain.',\n",
       "  'labels': ['Bad', 'Neutral', 'Good'],\n",
       "  'scores': [0.9385144114494324, 0.04435691237449646, 0.017128674313426018]},\n",
       " {'sequence': 'Here is a bus stop.',\n",
       "  'labels': ['Good', 'Bad', 'Neutral'],\n",
       "  'scores': [0.5775772929191589, 0.2158556431531906, 0.20656703412532806]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier([\"It is a good day!\", \"I feel pain.\", \"Here is a bus stop.\"],\n",
    "           candidate_labels=[\"Good\", \"Bad\", \"Neutral\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The sky is blue. The air is clean. I\\'m very nervous,\" he said.\\n\\nThe night before he flew from Toronto in 2002 to'},\n",
       " {'generated_text': 'The sky is blue. The air is clean. I can feel my skin puffing up like a butterfly. I can feel the scent of perfume coming'},\n",
       " {'generated_text': \"The sky is blue. The air is clean. I've been at that since I was a kidâ€”it was my first, I'm sure.\"},\n",
       " {'generated_text': \"The sky is blue. The air is clean. I'm fine.\\n\\n'You can't get through this... There's got to be something\"},\n",
       " {'generated_text': 'The sky is blue. The air is clean. I\\'ve never been happier.\\n\\n\"I have a dream to play for the U.S'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more model choices: https://huggingface.co/models?pipeline_tag=text-generation&sort=trending\n",
    "# use parameter: model=\"distilgpt2\" for example in the pipeline\n",
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"The sky is blue. The air is clean. I\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.14843003451824188,\n",
       "   'token': 2341,\n",
       "   'token_str': ' train',\n",
       "   'sequence': '<s>I have my ticket in my hand and go to the train station in the<mask> on Monday.</s>'},\n",
       "  {'score': 0.1326620876789093,\n",
       "   'token': 8511,\n",
       "   'token_str': ' polling',\n",
       "   'sequence': '<s>I have my ticket in my hand and go to the polling station in the<mask> on Monday.</s>'},\n",
       "  {'score': 0.09672749787569046,\n",
       "   'token': 12309,\n",
       "   'token_str': ' petrol',\n",
       "   'sequence': '<s>I have my ticket in my hand and go to the petrol station in the<mask> on Monday.</s>'},\n",
       "  {'score': 0.07378963381052017,\n",
       "   'token': 12716,\n",
       "   'token_str': ' metro',\n",
       "   'sequence': '<s>I have my ticket in my hand and go to the metro station in the<mask> on Monday.</s>'},\n",
       "  {'score': 0.07304640859365463,\n",
       "   'token': 2353,\n",
       "   'token_str': ' bus',\n",
       "   'sequence': '<s>I have my ticket in my hand and go to the bus station in the<mask> on Monday.</s>'}],\n",
       " [{'score': 0.10222644358873367,\n",
       "   'token': 662,\n",
       "   'token_str': ' morning',\n",
       "   'sequence': '<s>I have my ticket in my hand and go to the<mask> station in the morning on Monday.</s>'},\n",
       "  {'score': 0.08518318086862564,\n",
       "   'token': 343,\n",
       "   'token_str': ' city',\n",
       "   'sequence': '<s>I have my ticket in my hand and go to the<mask> station in the city on Monday.</s>'},\n",
       "  {'score': 0.05937575176358223,\n",
       "   'token': 15715,\n",
       "   'token_str': ' CBD',\n",
       "   'sequence': '<s>I have my ticket in my hand and go to the<mask> station in the CBD on Monday.</s>'},\n",
       "  {'score': 0.05312139540910721,\n",
       "   'token': 1559,\n",
       "   'token_str': ' evening',\n",
       "   'sequence': '<s>I have my ticket in my hand and go to the<mask> station in the evening on Monday.</s>'},\n",
       "  {'score': 0.052546340972185135,\n",
       "   'token': 1390,\n",
       "   'token_str': ' afternoon',\n",
       "   'sequence': '<s>I have my ticket in my hand and go to the<mask> station in the afternoon on Monday.</s>'}]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask')\n",
    "unmasker(\"I have my ticket in my hand and go to the <mask> station in the <mask> on Monday.\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'LOC',\n",
       "  'score': 0.99516475,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 36,\n",
       "  'end': 44},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99941057,\n",
       "  'word': 'New York',\n",
       "  'start': 48,\n",
       "  'end': 56},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.96700656,\n",
       "  'word': 'Government Center',\n",
       "  'start': 92,\n",
       "  'end': 109}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"In the morning, I took a train from Brooklyn to New York city center. My office is near the Government Center station.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.99716336,\n",
       "  'word': 'Tom',\n",
       "  'start': 12,\n",
       "  'end': 15}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"A boy named Tom goes to school, next generation school of brooklyn. He has a teach, alice, who teaches him math and science.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.99837106,\n",
       "  'word': 'Tom',\n",
       "  'start': 12,\n",
       "  'end': 15},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.92821395,\n",
       "  'word': 'Next Generation School of Brooklyn',\n",
       "  'start': 32,\n",
       "  'end': 66},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.9964515,\n",
       "  'word': 'Alice',\n",
       "  'start': 84,\n",
       "  'end': 89}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"A boy named Tom goes to school, Next Generation School of Brooklyn. He has a teach, Alice, who teaches him math and science.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9579741358757019, 'start': 25, 'end': 31, 'answer': 'London'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = pipeline(\"question-answering\")\n",
    "qa(\n",
    "    question=\"What is the capital of France?\",\n",
    "    context=\"The capital of France is London. Oh... no, my bad, it is Paris.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Telopea speciosissima is a large shrub in the plant family Proteaceae . It is endemic to New South Wales in Australia and is the floral emblem of that state . The species is well renowned for its striking large red springtime inflorescences (flowerheads)'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarization = pipeline(\"summarization\")\n",
    "summarization(\n",
    "    \"\"\"\n",
    "    Telopea speciosissima, commonly known as the New South Wales waratah or\n",
    "    simply waratah, is a large shrub in the plant family Proteaceae. It is\n",
    "    endemic to New South Wales in Australia and is the floral emblem of that\n",
    "    state. No subspecies are recognised, but the closely related Telopea aspera\n",
    "    was only recently classified as a separate species. T. speciosissima is a\n",
    "    shrub to 3 or 4 m (9.8 or 13.1 ft) high and 2 m (6.6 ft) wide, with dark\n",
    "    green leaves. Its several stems arise from a pronounced woody base known as\n",
    "    a lignotuber. The species is well renowned for its striking large red\n",
    "    springtime inflorescences (flowerheads), each including hundreds of\n",
    "    individual flowers. These are visited by the eastern pygmy possum\n",
    "    (Cercartetus nanus), birds such as honeyeaters (Meliphagidae), and various\n",
    "    insects.\n",
    "    \n",
    "    The floral emblem for its home state of New South Wales, Telopea\n",
    "    speciosissima has featured prominently in art, architecture, and\n",
    "    advertising, particularly since Australian federation. Commercially grown in\n",
    "    several countries as a cut flower, it is also cultivated in home gardens,\n",
    "    requiring good drainage yet adequate moisture, but is vulnerable to various\n",
    "    fungal diseases and pests. A number of cultivars with various shades of red,\n",
    "    pink and even white flowers are available. Horticulturists have also\n",
    "    developed hybrids with T. oreades and T. mongaensis which are more tolerant\n",
    "    of cold, shade, and heavier soils.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-base and revision 686f1db (https://huggingface.co/google-t5/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Hugging Face ist ein Technologieunternehmen mit Sitz in New York und Paris.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = pipeline(\"translation_en_to_de\")\n",
    "translator(\"Hugging Face is a technology company based in New York and Paris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
